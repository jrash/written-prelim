@article{Applied,
author = {Applied, S T and Analysis, Bayesian},
file = {:C$\backslash$:/Users/Vestige/Downloads/DR.pdf:pdf},
number = {11},
title = {{( 11 ) Case Studies : Bayesian analysis of dose-response curves EPA ToxCast data}}
}
@article{Bates1988,
abstract = {The prelims comprise: * Half Title * Title * Preface * Contents},
author = {Bates, Douglas M. and Watts, Donald G.},
doi = {10.1002/9780470316757},
file = {:C$\backslash$:/Users/Vestige/Downloads/nraia2.pdf:pdf},
isbn = {9780470316757},
issn = {01621459},
journal = {New York: Wiley},
number = {410},
pages = {594},
pmid = {121},
title = {{Nonlinear Regression Analysis and Its Applications}},
url = {http://www.jstor.org/stable/2289810?origin=crossref{\%}5Cnhttp://doi.wiley.com/10.1002/9780470316757},
volume = {85},
year = {1988}
}
@article{Bystritskaya,
abstract = {SUMMARY Non-linear regression (NLR) analysis in chemometric applications is the main subject of the paper. The following novel items of NLR procedure are reported. The modification of gradient method is considered. For inversion of the Fisher matrix the recurrence algorithm based on the matrix exponential is used. A new method of sequential Bayesian estimation allows processing of the data successively for every response. Each data set is fitted individually, but taking into account the information about common parameters estimated on previous data sets. A posterior Bayesian distribution is built after every set processing. A new method of confidence estimation is suggested. Unlike bootstrap, not initial data but parameter estimates are simulated. This method has the same accuracy as bootstrap but is about 1000 times faster. A new coefficient of non-linearity is introduced. It is calculated by the Monte Carlo procedure and accounts for the model structure as well as the experimental design features. All new ideas were implemented in the software FITTER, a new Excel Add-In. Its main capabilities are reported. The paper is illustrated with a number of practical examples in DSC, TMA and TGA data analysis.},
author = {Bystritskaya, E V and Pomerantsev, A L and {Ye Rodionova}, O},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bystritskaya, Pomerantsev, Ye Rodionova - Unknown - Non-linear regression analysis new approach to traditional implementations.pdf:pdf},
keywords = {FITTER Add-In for Excel,coefficient of non-linearity,confidence intervals,non-linear regression},
title = {{Non-linear regression analysis: new approach to traditional implementations}},
url = {http://rcs.chemometrics.ru/papers/J14{\_}667.pdf}
}
@article{Crawley2002,
abstract = {Linear models -- Generalized linear models -- Introducing GAM's -- Some GAM theory -- GAMs in practice: mgcv -- Mixed models and GAMMs.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Crawley, M J},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Crawley - 2002 - Generalized Additive Models.pdf:pdf},
isbn = {978-1-4987-2833-1},
issn = {01679473},
journal = {Statistical Computing: An Introduction to Data Analysis using S-Plus},
keywords = {Generalized additive model,MODELS},
pages = {694--704},
pmid = {891670},
title = {{Generalized Additive Models}},
year = {2002}
}
@techreport{draper1974effects,
author = {Draper, Norman R and Shaw, Douglas E},
institution = {WISCONSIN UNIV MADISON MATHEMATICS RESEARCH CENTER},
title = {{The Effects of Nonlinearity in Regression Models. Part 1. A Procedure for Examination of Adequacy of the Linear Approximation.}},
year = {1974}
}
@article{Dude,
author = {Dude},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(14).pdf:pdf},
title = {{Bootstrapping regression models}}
}
@article{Duncan1978,
abstract = {A jackknife procedure for constructing confidence regions in nonlinear regression is examined using Monte Carlo simulation. The jackknife promises to be asymptotically double-edged, being both independent of linearizing approximations to the regression surface and insensitive to specification of the error distribution. For moderate sample sizes the jackknife cannot be trusted in establishing joint confidence regions.},
author = {Duncan, George T.},
doi = {10.1080/00401706.1978.10489636},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Duncan - 1978 - An empirical study of jackknife-constructed confidence regions in nonlinear regression.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Confidence regions,Estimation,Jack knife,Least squares,Monte carlo,Nonlinear regression},
title = {{An empirical study of jackknife-constructed confidence regions in nonlinear regression}},
year = {1978}
}
@article{Eck2017,
abstract = {The multivariate linear regression model is an important tool for investigating relationships between several response variables and several predictor variables. The primary interest is in inference about the unknown regression coefficient matrix. We propose multivariate bootstrap techniques as a means for making inferences about the unknown regression coefficient matrix. These bootstrapping techniques are extensions of those developed in Freedman [1981], which are only appropriate for univariate responses. Extensions to the multivariate linear regression model are made without proof. We formalize this exten-sion and prove its validity. A real data example and two simulated data examples which offer some finite sample verification of our theoretical results are provided.},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.07040v2},
author = {Eck, Daniel J},
eprint = {arXiv:1704.07040v2},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Eck - 2017 - Bootstrapping for multivariate linear regression models.pdf:pdf},
keywords = {Multivariate Bootstrap,Multivariate Linear Regression Model,Residual Bootstrap},
title = {{Bootstrapping for multivariate linear regression models}},
url = {https://arxiv.org/pdf/1704.07040.pdf},
year = {2017}
}
@article{Efron1981,
abstract = {We discuss several nonparametric methods for attaching a standard error to a point estimate: the jackknife, the bootstrap, half-sampling, subsampling, balanced repeated replications, the infinitesimal jackknife, influence function techniques and the delta method. The last three methods are shown to be identical. All the methods derive from the same basic idea, which is also the idea underlying the common parametric methods. Extended numerical comparisons are made for the special case of the correlation coefficient.},
author = {Efron, Bradley},
file = {:C$\backslash$:/Users/Vestige/Downloads/2335441.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {589--599},
title = {{Biometrika Trust Nonparametric Estimates of Standard Error : The Jackknife , the Bootstrap and Other Methods Author ( s ): Bradley Efron Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : http://www.jstor.org/stable/2335441}},
volume = {68},
year = {1981}
}
@misc{Elzhov2016,
annote = {R package version 1.2-1},
author = {Elzhov, Timur V and Mullen, Katharine M and Spiess, Andrej-Nikolai and Bolker, Ben},
title = {{minpack.lm: R Interface to the Levenberg-Marquardt Nonlinear Least-Squares Algorithm Found in MINPACK, Plus Support for Bounds}},
url = {https://cran.r-project.org/package=minpack.lm},
year = {2016}
}
@article{Freedman,
author = {Freedman},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(13).pdf:pdf},
title = {bootstrapping regression models}
}
@book{huet2006statistical,
author = {Huet, Sylvie and Bouvier, Anne and Poursat, Marie-Anne and Jolivet, Emmanuel},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huet et al. - 2006 - Statistical tools for nonlinear regression a practical guide with S-PLUS and R examples.pdf:pdf},
publisher = {Springer Science {\&} Business Media},
title = {{Statistical tools for nonlinear regression: a practical guide with S-PLUS and R examples}},
year = {2006}
}
@article{Lyles2009,
author = {Lyles},
doi = {10.1016/j.cct.2008.05.009.NONLINEAR},
file = {:C$\backslash$:/Users/Vestige/Downloads/nihms77514.pdf:pdf},
number = {6},
pages = {878--886},
title = {{Involving Continuous Therapeutic Dose-Response}},
volume = {29},
year = {2009}
}
@article{Man2018,
abstract = {A parametric bootstrap estimate (PB) may be more accurate than its non-parametric version (NB) if the parametric model upon which it is based is, at least approximately, correct. Construction of an optimal estimator based on both PB and NB is pursued with the aim of minimizing the mean squared error. Our approach is to pick an empirical estimate of the optimal tuning parameter ee[0,1] which minimizes the mean square error of eNB + (1 â€” e) PB. The resulting hybrid estimator is shown to be more reliable than either PB or NB uniformly over a rich class of distributions. Theoretical asymptotic results show that the asymptotic error of this hybrid estimator is quite close in distribution to the smaller of the errors of PB and NB. All these errors typically have the same convergence rate of order O(n{\~{}}{\~{}}{\%}). A particular example is also presented to illustrate the fact that this hybrid estimate can indeed be strictly better than either of the pure bootstrap estimates in terms of minimizing mean squared error. Two simulation studies were conducted to verify the theoretical results and demonstrate the good practical performance of the hybrid method. 1. Introduction The idea of bootstrapping in statistical estimation was put forward by Efron[2]. The bootstrap method can be applied in both parametric and non-parametric fashions. In the context of estimation of a statistical functional a(F) based on a random sample of size n from an unknown distribution F, the parametric bootstrap estimate (PB) and the non-parametric bootstrap estimate (NB) amount to replacing F by F and F n respectively, where 8 n is some estimate of the index 8 parametrizing a family {\{}F 6 {\}} thought to contain F, and F n is the usual empirical distribution with equal probability placed on each data point. In the literature PB and NB have been discussed mainly as two quite separate procedures. Their relative performance depends largely on correctness of our assumption of the parametric model. The estimate PB is generally more accurate if our proposed model is sufficiently close to F, whereas NB is the better choice if the parametric model is far from correct. The question of which one to use in circumstances where knowledge of the underlying distribution is vague remains unanswered. A straightforward criterion to guide our choice between the two bootstrap estimates is necessary. Hjort[5] looks briefly at an intermediate bootstrap estimate (IB) obtained by replacing F with a mixture distribution eF{\$} +(l â€” e)F n , where ee[0,},
author = {Man, Stephen and Lee, Sing},
doi = {10.1017/S0305004100072121},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Man, Lee - 2018 - Optimal choice between parametric and non-parametric bootstrap estimates(2).pdf:pdf},
journal = {Math. Proc. Camb. Phil. Soc},
number = {335},
pages = {3--3},
title = {{Optimal choice between parametric and non-parametric bootstrap estimates}},
url = {https://www-cambridge-org.prox.lib.ncsu.edu/core/services/aop-cambridge-core/content/view/CB663F1FD1814F1CA4D67546EE247F3C/S0305004100072121a.pdf/optimal{\_}choice{\_}between{\_}parametric{\_}and{\_}nonparametric{\_}bootstrap{\_}estimates.pdf},
volume = {115},
year = {2018}
}
@article{Marra2011,
abstract = {We study the coverage properties of Bayesian confidence intervals for the smooth component functions of generalized additive models (GAMs) represented using any penalized regression spline approach. The intervals are the usual generalization of the intervals first proposed by Wahba and Silverman in 1983 and 1985, respectively, to the GAM component context. We present simulation evidence showing these intervals have close to nominal 'across-the-function' frequentist coverage probabilities, except when the truth is close to a straight line/plane function. We extend the argument introduced by Nychka in 1988 for univariate smoothing splines to explain these results. The theoretical argument suggests that close to nominal coverage probabilities can be achieved, provided that heavy oversmoothing is avoided, so that the bias is not too large a proportion of the sampling variability. Otherwise, because the Bayesian intervals account for bias and variance, the coverage probabilities are surprisingly insensitive to the exact choice of smoothing parameter. The theoretical results allow us to derive alternative intervals from a purely frequentist point of view, and to explain the impact that the neglect of smoothing parameter variability has on confidence interval performance. They also suggest switching the target of inference for component-wise intervals away from smooth components in the space of the GAM identifiability constraints. Instead intervals should be produced for each function as if only the other model terms were subject to identifiability constraints. If this is done then coverage probabilities are improved.},
author = {Marra, Giampiero and Wood, Simon N},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marra, Wood - 2011 - Coverage Properties of Confidence Intervals for Generalized Additive Model Components.pdf:pdf},
keywords = {Bayesian confidence interval,Generalized additive model,Penalized regression spline},
title = {{Coverage Properties of Confidence Intervals for Generalized Additive Model Components *}},
url = {http://opus.bath.ac.uk/26662/1/MarraWoodCI.pdf},
year = {2011}
}
@incollection{More1978,
abstract = {Work performed under the auspices of the U.S. Energy Research and Development Administration},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.06106v1},
author = {Mor{\'{e}}, Jorge J.},
doi = {10.1007/BFb0067700},
eprint = {arXiv:1502.06106v1},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mor{\'{e}} - 1978 - The Levenberg-Marquardt algorithm Implementation and theory.pdf:pdf},
isbn = {978-3-540-08538-6},
issn = {1617-9692},
pmid = {25246403},
title = {{The Levenberg-Marquardt algorithm: Implementation and theory}},
year = {1978}
}
@book{P.Murphy1991,
abstract = {Some of the most remarkable issues related to interharmonics observed from a probabilistic perspective are presented. Attention is firstly devoted to interharmonic frequency and amplitude variability. Starting from the basic mathematical and computational aspects of probabilistic harmonic models, the difficulties to include interharmonics are discussed with particular attention to the problem of the frequency resolution and of the computational burden. Then, simulation and measurement aspects are discussed, also showing some numerical and experimental results.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {{P. Murphy}, Kevin},
booktitle = {Machine Learning: A Probabilistic Perspective},
doi = {10.1007/SpringerReference_35834},
eprint = {0-387-31073-8},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/P. Murphy - 1991 - Machine Learning A Probabilistic Perspective.pdf:pdf},
isbn = {9780262018029},
issn = {0262018020},
pages = {73--78,216--244},
pmid = {20236947},
title = {{Machine Learning: A Probabilistic Perspective}},
url = {http://link.springer.com/chapter/10.1007/978-94-011-3532-0{\_}2},
year = {1991}
}
@article{Peddada2005,
author = {Peddada, Shyamal and Haseman, Joseph},
doi = {10.2203/dose-response.003.03.005},
file = {:C$\backslash$:/Users/Vestige/Downloads/hormes-03-342.pdf:pdf},
issn = {1559-3258},
journal = {Dose-Response},
keywords = {confidence interval,coverage probability,variance estimation},
number = {3},
pages = {342--352},
title = {{Analysis Of Nonlinear Regression Models: A Cautionary Note}},
url = {http://dos.sagepub.com/lookup/doi/10.2203/dose-response.003.03.005},
volume = {3},
year = {2005}
}
@article{Reich,
author = {Reich, Brian J},
file = {:C$\backslash$:/Users/Vestige/Downloads/GP.pdf:pdf},
number = {4},
pages = {1--15},
title = {{Non-linear / non-parametric regression}}
}
@article{Ruckstuhl,
author = {Ruckstuhl, Andreas},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruckstuhl - Unknown - Nonlinear Regression A Powerful Tool With Considerable Complexity Half-Day 3 Bootstrap, Prediction and Calibration.pdf:pdf},
title = {{Nonlinear Regression: A Powerful Tool With Considerable Complexity Half-Day 3: Bootstrap, Prediction and Calibration}},
url = {https://www.ethz.ch/content/dam/ethz/special-interest/math/statistics/sfs/Education/Advanced Studies in Applied Statistics/course-material/robust-nonlinear/06{\_}nlregFolien16-HT3{\_}Druck.pdf}
}
@article{Ruckstuhl2010,
author = {Ruckstuhl, Andreas},
doi = {10.1007/978-3-319-33455-4},
file = {:C$\backslash$:/Users/Vestige/Downloads/nlreg10E.pdf:pdf},
isbn = {978-3-319-33454-7},
journal = {ZHAW Z{\"{u}}rcher Hochschule f{\"{u}}r Angewandte Wissenschaften},
number = {October},
title = {{Introduction to Nonlinear Regression}},
url = {http://stat.ethz.ch/{~}stahel/courses/cheming/nlreg10E.pdf{\%}0Ahttp://link.springer.com/10.1007/978-3-319-33455-4},
volume = {1},
year = {2010}
}
@article{Simonoff1986,
author = {Simonoff, Jeffrey S. and Tsai, Chih-Ling},
doi = {10.1080/00401706.1986.10488111},
issn = {0040-1706},
journal = {Technometrics},
month = {may},
number = {2},
pages = {103--112},
title = {{Jackknife-Based Estimators and Confidence Regions in Nonlinear Regression}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1986.10488111},
volume = {28},
year = {1986}
}
@book{Wickham,
author = {Wickham, Hadley and Gentleman, Robert and Hornik, Kurt and Parmigiani, Giovanni and Wickham, Hadley and Gentleman, Robert and Hornik, Kurt and Parmigiani, Giovanni},
file = {:C$\backslash$:/Users/Vestige/Downloads/document.pdf:pdf},
isbn = {9780387981406},
title = {{Use R!}}
}
@article{Wilson2013,
author = {Wilson, Ander and Reif, David M and Reich, Brian J and Carolina, North and Carolina, North},
file = {:C$\backslash$:/Users/Vestige/Downloads/biom12114-sm-0001-suppdata.pdf:pdf},
number = {September},
pages = {0--10},
title = {{Supplemental Material for Hierarchical Dose-Response Modeling for High-Throughput Toxicity Screening of Environmental Chemicals}},
year = {2013}
}
@article{Wilson2014,
author = {Wilson, Ander and Reif, David M and Reich, Brian J and Carolina, North and Carolina, North and Carolina, North and Carolina, North},
doi = {10.1111/biom.12114},
file = {:C$\backslash$:/Users/Vestige/Downloads/Wilson{\_}et{\_}al-2014-Biometrics.pdf:pdf},
keywords = {bayesian,computational toxicology,dose,mcmc,monotonicity,response,semiparametric,toxcast},
number = {March},
pages = {237--246},
title = {{Hierarchical Dose â€“ Response Modeling for High-Throughput Toxicity Screening of Environmental Chemicals}},
year = {2014}
}
@book{fox2015applied,
  title={Applied regression analysis and generalized linear models},
  author={Fox, John},
  year={2015},
  publisher={Sage Publications}
}
@book{wood2017generalized,
  title={Generalized additive models: an introduction with R},
  author={Wood, Simon N},
  year={2017},
  publisher={CRC press}
}
@book{james2013introduction,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume={112},
  year={2013},
  publisher={Springer}
}